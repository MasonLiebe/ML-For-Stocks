{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'jupyter-server-r444rqj4wp95fxxr7'. Verify the server is running and reachable. (Connection got disposed.). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Modeling Parameters and Fetch Data\n",
    "\n",
    "Enter a ticker and date range you would like to build the model on.  This model takes a a single ticker's data.  Also enter a training size for the proportion of the data you want to include in your training set vs. your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock configs\n",
    "ticker = ['TSLA']\n",
    "start_date = '2015-04-01'\n",
    "end_date = '2024-04-05'\n",
    "\n",
    "# model configs\n",
    "train_size = 0.8\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 30  # Number of past days we want to use to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2268, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>12.580000</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>12.403333</td>\n",
       "      <td>12.506000</td>\n",
       "      <td>56919000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>12.682000</td>\n",
       "      <td>12.882000</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>12.733333</td>\n",
       "      <td>75156000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>13.850000</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>13.540000</td>\n",
       "      <td>186837000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>13.500667</td>\n",
       "      <td>13.670667</td>\n",
       "      <td>13.409333</td>\n",
       "      <td>13.550000</td>\n",
       "      <td>65218500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-08</td>\n",
       "      <td>13.880000</td>\n",
       "      <td>14.060000</td>\n",
       "      <td>13.724667</td>\n",
       "      <td>13.844667</td>\n",
       "      <td>94546500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close     Volume  \\\n",
       "0 2015-04-01  12.580000  12.820000  12.403333  12.506000   56919000   \n",
       "1 2015-04-02  12.682000  12.882000  12.666667  12.733333   75156000   \n",
       "2 2015-04-06  13.200000  13.850000  13.166667  13.540000  186837000   \n",
       "3 2015-04-07  13.500667  13.670667  13.409333  13.550000   65218500   \n",
       "4 2015-04-08  13.880000  14.060000  13.724667  13.844667   94546500   \n",
       "\n",
       "   Dividends  Stock Splits  \n",
       "0        0.0           0.0  \n",
       "1        0.0           0.0  \n",
       "2        0.0           0.0  \n",
       "3        0.0           0.0  \n",
       "4        0.0           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Fetching\n",
    "data = fetch_stock_data(ticker, start_date, end_date)[ticker[0]]\n",
    "data.reset_index(drop=False, inplace=True)\n",
    "data['Date'] = pd.to_datetime(data['Date']).dt.tz_localize(None)\n",
    "\n",
    "print(data.shape)\n",
    "included_days = len(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Build\n",
    "Here I build an actor-critic agent that signals actions in a trading enviroment, trained and tested on your given ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, name, input_size, output_size, size_layer):\n",
    "        super(Actor, self).__init__()\n",
    "        with tf.name_scope(name):\n",
    "            self.dense1 = tf.keras.layers.Dense(size_layer, activation='relu')\n",
    "            self.dense2 = tf.keras.layers.Dense(output_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        logits = self.dense2(x)\n",
    "        return logits\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, name, input_size, output_size, size_layer):\n",
    "        super(Critic, self).__init__()\n",
    "        with tf.name_scope(name):\n",
    "            self.dense1 = tf.keras.layers.Dense(size_layer, activation='relu')\n",
    "            self.dense2 = tf.keras.layers.Dense(output_size, activation='relu')\n",
    "            self.dense3 = tf.keras.layers.Dense(size_layer//2, activation='relu')\n",
    "            self.dense4 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, y):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x) + y\n",
    "        x = self.dense3(x)\n",
    "        logits = self.dense4(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    LEARNING_RATE = 0.001\n",
    "    BATCH_SIZE = 32\n",
    "    LAYER_SIZE = 256\n",
    "    OUTPUT_SIZE = 3\n",
    "    EPSILON = 0.5\n",
    "    DECAY_RATE = 0.005\n",
    "    MIN_EPSILON = 0.1\n",
    "    GAMMA = 0.99\n",
    "    MEMORIES = deque()\n",
    "    MEMORY_SIZE = 300\n",
    "    COPY = 1000\n",
    "    T_COPY = 0\n",
    "\n",
    "    def __init__(self, state_size, window_size, trend, skip):\n",
    "        self.state_size = state_size\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.trend = trend\n",
    "        self.skip = skip\n",
    "        self.actor = Actor('actor-original', self.state_size, self.OUTPUT_SIZE, self.LAYER_SIZE)\n",
    "        self.actor_target = Actor('actor-target', self.state_size, self.OUTPUT_SIZE, self.LAYER_SIZE)\n",
    "        self.critic = Critic('critic-original', self.state_size, self.OUTPUT_SIZE, self.LAYER_SIZE)\n",
    "        self.critic_target = Critic('critic-target', self.state_size, self.OUTPUT_SIZE, self.LAYER_SIZE)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(self.LEARNING_RATE)\n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(self.LEARNING_RATE)\n",
    "\n",
    "    def _assign(self, from_model, to_model):\n",
    "        for from_layer, to_layer in zip(from_model.layers, to_model.layers):\n",
    "            to_layer.set_weights(from_layer.get_weights())\n",
    "\n",
    "    def _memorize(self, state, action, reward, new_state, dead):\n",
    "        self.MEMORIES.append((state, action, reward, new_state, dead))\n",
    "        if len(self.MEMORIES) > self.MEMORY_SIZE:\n",
    "            self.MEMORIES.popleft()\n",
    "\n",
    "    def _select_action(self, state):\n",
    "        if np.random.rand() < self.EPSILON:\n",
    "            action = np.random.randint(self.OUTPUT_SIZE)\n",
    "        else:\n",
    "            state_tensor = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "            logits = self.actor(state_tensor)\n",
    "            action = tf.argmax(logits[0]).numpy()\n",
    "        return action\n",
    "\n",
    "    def _construct_memories_and_train(self, replay):\n",
    "        states = np.array([a[0] for a in replay])\n",
    "        new_states = np.array([a[3] for a in replay])\n",
    "        Q = self.actor(states)\n",
    "        Q_target = self.actor_target(states)\n",
    "        rewards = np.array([a[2] for a in replay]).reshape((-1, 1))\n",
    "        rewards_target = self.critic_target(new_states, Q_target)\n",
    "        for i in range(len(replay)):\n",
    "            if not replay[0][-1]:\n",
    "                rewards[i] += self.GAMMA * rewards_target[i]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values = self.critic(states, Q)\n",
    "            critic_loss = tf.reduce_mean(tf.square(rewards - q_values))\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grad, self.critic.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.actor(states)\n",
    "            actor_loss = -tf.reduce_mean(self.critic(states, logits))\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(zip(actor_grad, self.actor.trainable_variables))\n",
    "\n",
    "        return critic_loss\n",
    "\n",
    "    def get_state(self, t):\n",
    "        window_size = self.window_size + 1\n",
    "        d = t - window_size + 1\n",
    "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
    "        res = []\n",
    "        for i in range(window_size - 1):\n",
    "            res.append(block[i + 1] - block[i])\n",
    "        return np.array(res)\n",
    "\n",
    "    def buy(self, initial_money):\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        state = self.get_state(0)\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self._select_action(state)\n",
    "            next_state = self.get_state(t + 1)\n",
    "\n",
    "            if action == 1 and initial_money >= self.trend[t]:\n",
    "                inventory.append(self.trend[t])\n",
    "                initial_money -= self.trend[t]\n",
    "                states_buy.append(t)\n",
    "                print('day %d: buy 1 unit at price %f, total balance %f'% (t, self.trend[t], initial_money))\n",
    "\n",
    "            elif action == 2 and len(inventory):\n",
    "                bought_price = inventory.pop(0)\n",
    "                initial_money += self.trend[t]\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((self.trend[t] - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print(\n",
    "                    'day %d, sell 1 unit at price %f, investment %f %%, total balance %f,'\n",
    "                    % (t, self.trend[t], invest, initial_money)\n",
    "                )\n",
    "\n",
    "            state = next_state\n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        total_gains = initial_money - starting_money\n",
    "        return states_buy, states_sell, total_gains, invest\n",
    "\n",
    "    def train(self, iterations, checkpoint, initial_money):\n",
    "        for i in range(iterations):\n",
    "            total_profit = 0\n",
    "            inventory = []\n",
    "            state = self.get_state(0)\n",
    "            starting_money = initial_money\n",
    "            for t in range(0, len(self.trend) - 1, self.skip):\n",
    "                if (self.T_COPY + 1) % self.COPY == 0:\n",
    "                    self._assign(self.actor, self.actor_target)\n",
    "                    self._assign(self.critic, self.critic_target)\n",
    "\n",
    "                action = self._select_action(state)\n",
    "                next_state = self.get_state(t + 1)\n",
    "\n",
    "                if action == 1 and starting_money >= self.trend[t]:\n",
    "                    inventory.append(self.trend[t])\n",
    "                    starting_money -= self.trend[t]\n",
    "\n",
    "                elif action == 2 and len(inventory) > 0:\n",
    "                    bought_price = inventory.pop(0)\n",
    "                    total_profit += self.trend[t] - bought_price\n",
    "                    starting_money += self.trend[t]\n",
    "\n",
    "                invest = ((starting_money - initial_money) / initial_money)\n",
    "\n",
    "                self._memorize(state, action, invest, next_state, starting_money < initial_money)\n",
    "                state = next_state\n",
    "                batch_size = min(len(self.MEMORIES), self.BATCH_SIZE)\n",
    "                replay = random.sample(self.MEMORIES, batch_size)\n",
    "                cost = self._construct_memories_and_train(replay)\n",
    "                self.T_COPY += 1\n",
    "                self.EPSILON = self.MIN_EPSILON + (1.0 - self.MIN_EPSILON) * np.exp(-self.DECAY_RATE * i)\n",
    "            if (i+1) % checkpoint == 0:\n",
    "                print('epoch: %d, total rewards: %f.3, cost: %f, total money: %f'%(i + 1, total_profit, cost, starting_money))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = data.Close.values.tolist()\n",
    "initial_money = 10000\n",
    "window_size = 30\n",
    "skip = 1\n",
    "batch_size = 32\n",
    "agent = Agent(state_size = window_size, \n",
    "              window_size = window_size, \n",
    "              trend = close, \n",
    "              skip = skip)\n",
    "agent.train(iterations = 10, checkpoint = 1, initial_money = initial_money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_buy, states_sell, total_gains, invest = agent.buy(initial_money = initial_money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "plt.plot(close, color='r', lw=2.)\n",
    "plt.plot(close, '^', markersize=10, color='m', label = 'buying signal', markevery = states_buy)\n",
    "plt.plot(close, 'v', markersize=10, color='k', label = 'selling signal', markevery = states_sell)\n",
    "plt.title('total gains %f, total investment %f%%'%(total_gains, invest))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
